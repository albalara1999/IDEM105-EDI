{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4906eb7b-91bf-4763-b4ff-5847f4c81de6",
   "metadata": {},
   "source": [
    "# Computational Text Analysis Fundamentals\n",
    "\n",
    "[Click here](https://colab.research.google.com/github/senthilchandrasegaran/IDEM105-EDI/blob/main/02-comptext-fundamentals.ipynb) to open this notebook in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048abf89-a2a3-4a73-9a0a-464b6c83f331",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenization refers to the process of dividing a text into \"tokens\": words, parts of words, phrases, punctuations, or even sentences. The most common tokenization is at the level of words. A common strategy is to \"split\" the text wherever one encounters spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35523489-1931-4c28-82d2-36e99851792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    Our environment. 
Yeah. 
If I. Put it here, yeah. Does everyone? You're on the frame, baby. 
It's like .7. 
Oh yeah. Without does everyone appear there? 
OK. 
Maybe no, Elena, nothing. 
Are you? Will you be in it? 
Now she. 
We need to be really far, OK. 
We have to come up with three concepts and. One. So let's read this. OK, so I was thinking when we were talking about this in class about some kind of pixel art and I saw that they also include this here as an option for something that we could do. So that could be an. 
MHM. 
Idea. Nice. Yeah. Any other? 
Last night. 
Do you have any other ideas? Yeah. We could build some. Yeah. 
Oh yeah, make a little. Village or. Ohh you just some 3D modeling. 
Yeah, like. Ohh like the typical like building blocks that you would play with when you were a kid or something. 
Yeah. Yeah, like with the cards. But it might be fragile, so I think. 
We can try it. Yeah, it's more out of the books, yeah. Yes. Not that that I was doing this. I was also thinking about that. Yeah. 
Yeah, yeah, like a storyboard. 
Yeah. Yeah, that would be. Cute. It might be hard with four people. Or we can just divide tasks. 
OK. It's OK. 
So which which one of the ideas do you think like the three thing more fun or different? 
Yes. I think they work best. The building. Yeah, the the making an art thing. The model, the model, the model. 
Yeah. Yeah. Maybe we could decide on some shapes that. We want to. Maybe try to do we can maybe do a quick. Sketch. Maybe you can be make like a building or something out of the shapes that we can make. Does anyone have a pen? Or a pencil. Nothing. I didn't. I didn't bring my. Drawing anything. Yeah, one of these is. Fine. 
You have color. 
Wow. Let's see if this one is not going to, or maybe this one will transfer. Too much to the other page. 
Yeah, I see. You can try this but. I think it might run. 
So we can do the typical. A cube. Which would be our basic shape, and for this we would need how many faces does it have? 
Like. 
6. Then we could make. A triangle shape. Then we will have to fold. The. Post. 
OK. 
And this has four. 
No, but when those 3-4 and 5546. 
5. Yeah. And then we can also. Fold them no. We don't need to use one for each. I mean we can create the structures by folding them. Can you provide an example? There's a lot, but I know they know there's some kind of structures that do like like this and you can stack them. I think. 
Yeah. 
I need to see a visual example. What kind of origami like? Super, very yummy. I don't know. 
Should we come up with the? What the bigger shape should be first? Oh yeah. 
So what do we want to do like? 
Snowman. 
I think that's. That's gonna be hard. Yeah, you came. Went from a village to a snow. 
I'm in Christmas. 
Tree. 
Oh yeah. 
With a few blocks. For let's just do like a run a triangular shape and this could be blocks. 
And then we could decorate them, yeah. 
Yeah. Well, you will get the idea. Kind of looks like. Yeah, but we can cut, for example, a post it into a * shape and cut a few of them like brown to have the ornaments. 
Mm-hmm. 
And this doesn't look like a pyramid anymore. Yeah, that's. I mean. It's yellow so. 
Yeah, I can ask ID card like sometimes. They have extra posting. 
Yeah, they have green. Then that would be perfect. 
Or just pink to have a different color, yeah. 
No, there's no green. No. 
That's a lot of. 
I should have brought my yeah, that would be a little well, but you would only have to paint one. Out of like the. All of. Them. Like if you make a cube, you only. Yeah, yeah, yeah. 
Have to paint one face tiny ones like, yeah. But how are you going to make a cube? 
You can make. 
One like tiny ones or big. 
Yeah, maybe there's going to be a. Lot of work. 
Maybe that we that we can find an origami. Where you make cube. 
Out. 
Of one. Yeah. It's just tiny, though. 
Been possible. I'm sure it up because my phone is with that I'm sure you. 
And I start. I know that's small one. 
Health and their lives. And they. 
Ohk OK. No blue things. You need a piece of. OK, it's a bit. I don't know if you would see it because of my. Screen. I can't see it. I don't know. 
Yeah, I can see it. 
They will be small though. 
Yeah, I think that one like this. 
Let's write. Let's write. 
Is too small. 
Hello. Wait, wait. This is gone. Yeah, yeah, they would probably be small. 
But yeah, what did he do bottom up so. And and. 
First half and then. The HALFING to another half. This is like the origami workshop that. We did, yeah. Finally useful. So 1 and the. Other two, yeah. 
Yeah. The one that's sticking. 
Right. 
The right message there. Well, maybe. 
Has the screen protection. 
Some of the brightness. I hate that. We have these. What did he do? Now. It's. It's still the. OK, OK, OK. 
On the start on. 
The start, yeah, yeah. What is going on now? OK. Let's see if this is not too small. 
OK. 
We will have a minute. 
Now we have horses. 
Please. 
What? 
Yeah, he's just. He's creasing the from the corner of the. 
Let's see. 
Rotate. 
I feel like we did this. In the. Origami workshop. I think some of the movements are, yeah. 
His brother. 
He goes so fast. 
What? What? What? What? What, what? No, I completely missed. That you can. No, no, no. Did someone should I? 
I'm completely lost. 
Ohh it's like. 
OK. 
Like so. Now he's going to do. The. I see. 
To what here in Cleveland Square? Open rotate. 
All sides. But is he? No, I think this is. 
Repeat so many. 
For all of. 
Them I thank you. It's just gonna take a shower. 
For all of them. 
Yeah, it takes. 
Wait, wait, wait. It's it's going fine, it's going fine. 
But we need to make a trip. 
Yes, we don't have to make it that big. 
So many of those. 
OK, I'll go. Back. Should I go? 
Yeah. 
Back. I think he finished creasing all of them. Yeah, yeah. Along this line. Mine is not that. 
What? It's clear. You didn't have that. 
With corner, I think I'm doing it wrong. Wrong. I am busy. Wrong. Wait, no, this one. Wait. OK, I I have this. 
OK. 
OK. 
It's sticking. 
Wait, wait. I'm going to go. I'll. 
Right. 
Oh, OK. 
Wait, is this? 
Wait, no, I don't know what you did. Get halfway. Open it, no. 
This is not looking like what it. Should be. 
And mentor. 
OK. And then. What? OK, this is too complicated. There's no way we'll be able to do this. 
I really don't get that. 
Which side is actually? I didn't get it. 
You like my brain. But how is it possible that? He has, like already like a. 
Cube looking thing like this. 
Because it's like open. OK, stop. It's gonna be like this. 
Right. Yeah. So for what I thought. 
Mine. Just look at mine. Oh, I think. 
It looked like a triangle. Don't know what I did. Yeah, you're weird, but on the other side. And then. You're missing this. Here I'm here. Ah, ah. And then turn. Turn. Yeah. 
So everybody has that. 
Then fold along. 
Oh. Oh, no, no, no, no, no. No, wait, wait. Wait, wait, wait. Too fast, too fast. 
Too fast? OK. 
Bro what? What I don't even have that line. 
****. Ohh yeah, on this line it's it's the middle line, yeah. 
I don't. I'm lost. What made this one like like diagonal line? 
Like this line? There's a line in. The middle, like I don't have. This ohh wow. 
It's so tiny. 
The halfway line. Play by like those. Why are we doing this for ourselves? Yeah. 
OK. Again very slowly, slowly. 
Wait. 
Yeah. And there's a line in the. Middle like this line. 
Like inside like this. 
It's. 
It's this and you have a line inside and this. 
Yeah, yeah, yeah. Ah. What? How are you folding it? Are you folding in? 
I'm just for the. No, you just. 
This is so unnatural. Ah, I see. Like this? No. 
Yeah, you need to create a line in the middle. 
No, I don't get it. I have the line. But how are you folding the? We can create a. Tree with this. 
Yeah, I forgot which side this side. 
I think it's a like it's like this like. 
And then turn this side right, I think, yeah, you're having. 
This have to fall this like this. 
No, I think the the, the. 
Yeah. No. 
This it should be like this right? 
Ohh whoa. Yeah. And then you fold it, you have. 
Which side? I think you have the wrong side. 
Wait, can I have it? Maybe could be. I did it very fast. 
This this to be need to be like. Open. 
Toward ah, yeah, it's like this now. This is going to take us hours. Maybe we should do a different box. 
Yeah. 
Maybe we should use? 
Six, yeah, yeah. 
Of the student. Yeah, we could do 321. Yeah, 6:00 and 3:00. And we have a three. We have to finish this two. Yeah. 
Yeah, sorry. Yeah. I won't be able to sleep. 
No, no. 
This is too OK. Yeah, I did that. 
We just did that. 
OK. 
Oh. 
Oh. 
Yeah, yeah, yeah, I got this step finally. No, wait. I'm gonna go back. 
Everything. 
'S. 
OK. OK. Wait, wait. I got. I think so too, yes. 
I'm not folding like that. 
OK. 
And I go. Back, yeah, extra hard with the post the wallpaper, yeah. Obviously it's the fault of the paper. 
Yeah. What? Oh, you do. 
I'm missing a crease. Here. 
What? 
I don't know at this point. I just want. 
To close, we have. 
Yeah, yeah. OK. So yeah. 
So like this and then? 
Ohh he's opening it. 
What? No, wait, it's like this, OK? 
I didn't know it. 
So this is. Both. Yeah. Yeah. It's it's not. Yeah, it's. 
Wait, wait. We can. We're nearly done. We're nearly done. You you have this part. Already. 
Yeah, I have this part, but I. Just don't know like this whole and then. 
Yeah. Just fold it like. 
Yeah, I missed the middle part like. 
So he actually. I think I read that from. 
Yeah, like this. Already have this triangle and then. See this one is done and what's this? 
Yeah, it's just the top one top 1 here and he opens it up like this. OK, OK, I got this part. Wait, I'm going to go back again. 
So. I don't have a budget item wait. 
Yeah, I don't know about the album. 
It's those. Yeah. Yeah. Then you have do. Wait. This has to be folded here. So like I think. I think he's making it harder. 
Fold it. Yeah, yeah. 
All this. And. 
And can you do? And now this little fold. Here you open it. Up like this? 
OK God, can you help? 
I sold. 
This you have this. 
Yeah. 
And there's a saying in the middle. 
Yeah, yeah. 
Yeah. 
Yeah. Yeah, that's that's. This is. 
Yeah. 
Yes. 
This is. Ohh here and yeah, and this this block you have to get a hold this now so you have a block here. 
And then this. 
I have to do this. 
I think I give up. 
Like this any? 
But if we get tape. OK. 
Yeah, maybe. Let's look for any structure. What? I think I kind of got it. Well, kind of. Yeah, yeah. I just folded like The thing is inside. Of the other thing is. But there's one missing, so I didn't fully do it right. But we have kind of four. Dialogue. That even looks. Better. Perfect. Nice now. 
Just. 
No, we just need two more. Two. We're doing well. If you if you. 
Two, finish the How do you close the? 
I don't know, I guess. Can I try? Because I think it's more difficult to try. 
Yeah. 
To explain it. 
Or maybe you guys can do. It again if you. 
It's a practice from the origami workshop. Yeah. 
You don't know actually again. 
I'm gonna try again. You do that. You're wonderful. Well, I'll see if I can do something from memory professional, yeah. 
There's also the thing where you like draw the grid and then cut it out when you. Take it together. 
Is there? 
Using. Cube. Hi, sis. 
Oh. 
Right. 
I think you know. Yeah. Yeah, yeah, probably, yeah. 
Then you just fold it. 
But the papers that we have are. Too small for this one. 
Yeah, well, it might be the same size if you just take like if each block. 
Well, well, yeah, maybe. Yeah. We can try. But now we are obsessed with our leaders. We don't have. No. Now Eden and I were too invested in this. 
How many do we need? 
I don't know. I don't know. I did something different. It has some personality. There's some. Well, it works, it's fine, it works. Oh, wait, it holds. Yeah. OK. 
Yeah, you did it. How are you guys doing? 
OK, what did he do after having this thing like folding? It. 
Like in all size. 
The corner? Yes, like. This but you also need to show like. 
This from here as well. 
Ah yeah. I. If we did a a cloud of today. Of this would be like what? I wonder what the other groups are. Doing. 
Yeah, we're going. To be like this is our Christmas tree. 
They would. 
Definitely, yeah. Ours is going to be the cutest. I think the video is going to be longer. Than two minutes. 
Just cut the middle thing that we're folding. 
This yeah. I think that just we can just leave the discussion part. 
Is the video still gone? I think, yeah. 
Yes. OK. 
I think we can stop it for now, you know, because we're not doing any. We're just folding paper. We're not really doing any major thinking. Do we need the? But we already have more. Than two minutes of audio. That we need all the process in the end. Yeah, but now we have the process of when we folded 1. So now we're just doing the same process more times. That. Has to be recorded. I think just like in this. But they they want a 2 minute video recording, yeah. 
I. 
Need the audio to transcribe. OK, I got all those folks and then for God. Ohh yeah, yeah, yeah, yeah. And this. 
Now that we know well, we. Supposed to? Need to see them. OK, from this I don't remember what he did. 
And. 
Those and what? How? 
Like $5? Yeah. Like. See. Yeah. 
And then the strength and then this. 
Wait, wait, wait. You have it folded like this? 
And then. 
And the triangle. 
To the middle. Like less. Yeah. Yeah, yeah. That was under one step where he lived. But like wait, I think. I called it. In the wrong if it's possible to. 
And then click on this and then. 
Do you have the video? 
We need. 
No. I was. I try. I thought I could do it. But. I was lying to myself. 
Like this isn't the best. 
Yeah. When he finishes folding the whole thing. 
This one. But we can. 
Yeah, maybe. And if if he's still folding, yeah. 
Skip this part. 
Oh, I forgot to. 
Yeah, I forgot this as. Well. 
I think that's the crease that I was missing. Ohh yeah. OK. I'm getting hungry. 
Do you have class this afternoon? Ohh graduation. 
Oh yeah. 
What track do you have? Circular design? Nice. Put anything design, put anything, design experiences. And what is it? 
Experiences the one with the. 
Oh, that's cool. 
Let's see. What if we do just like this and we tape it together. And I think we can. Yeah, that's the pole that I was missing. 
I think they all did this. And you did this right? Yeah. OK, there you go. Although we already have. 
And. OK. 
And. 
Now. 
What is he doing? 
Now. 
Oh yeah, fold in. 
OK. 
This is as far as I don't understand. 
I think this part you did for me. But how did? He fold it in. Oh. This part I don't understand it. 
This. 
Wait. 
Can can I go back to where he's holding the middle thingy? 
Yes, this you don't have a line here. I think you have a line ohh. 
Yeah. What did I miss? 
Yeah. 
They are. 
Wait. You're willing? Just holding it like this. What? No. No, I don't. How did you solve this? 
Hmm. 
It's right so. Oh my God. I didn't. 
Yeah, yeah. 
Yeah. 
Ohh. 
Close. Yeah. 
You know. 
I got it. 
He's doing too many things right? 
Yeah. 
Oh my God. 
Do we have to? 
So for something simple along with it. No. 
Like that, got it. 
Yes. 
That was fun. I think I'm missing something. I feel like I'm at the end. I just. 
I don't know what to do after this. Rush just be like, OK, OK. 
Yeah. 
That it is the only. Right. 
Oh. 
Like this? 
OK. Right. Yeah, he does something really weird. OK. 
Well, which part is? 
We don't know. 
So we press in. Said. 
Can I? 
That. This is so funny. When people lose their masters. 
Yeah. 
Just had an existential. 
It's the second time that I follow. 
Yeah. 
I also did it for ITD so it's my third time fully. 
Nobody else. 
OK, I don't know. Do. You know how to do it. 
I don't know. I just I missed the middle. I'm missing only one, no. 
OK. We can take that. 
You can suck it here tomorrow. 
OK. 
How many of these do I need? 
OK, we're fine with the ones that we. Have now. 
This is who. 
You scroll that back, this one stays open. Twisted over. He presses the middle corner down. 2. 
Sounds. 
OK, it's kinda OK back corner down. 
I think I got it. 
I see. 
We're we're improving. No boy. 
OK so I have this. And then you start pressing the. Top. 
Yeah. And then this the other corner and like this corner, this is the first corner and then this is the corner. 
I think also. It's perfect. 
Yeah, I understand. 
Ohh. 
Then this corner. 
Well. Does anyone have data? This one can be fixed. 
Probably. Oh. No, no. Yeah. Talking where? OK, now I have all these. Yeah. And talking something. I just want to take the. It's. 
It's so difficult. 
Yeah, this one is fine too. 
On the paper. 
Well, we have 12345 and 6. So. Yeah, we can take this one. Too, and this one to do this by memory, so at least I can say you learned. I want. Ohh if she could have grabbed some scissors. Oh. I'm going to make ornaments. You're also going to. Make it with origami. Oh my God. Actually, no. I'm just gonna make. Them like this. No, I was thinking. That we could just cramp like goals. But they are not called paper like the color is not the paper is. 
Oh. 
Not color, yes. Regulation. Perfect. They're really pretty, yeah. 
Wait. 
Like a tree Christmas tree made out of presents. Yeah. 
Sorry, yeah. 
Let's fix the ones that are a bit falling apart. The tape you can make the star. But I will make. It will be small though. Let's try to. Fix. Oh nice. We're. Creative no one has seizures, so I can just cut. This with my hands. I'm making the ornaments. Trying to make this. Uh, we should also when we are, they are all like taped together we can. Also take them. With the red, you know, like these three, tape them together and then take the other. 
Ohh yeah. 
Ones. I'm sorry, are we allowed to use their material? 
I think it's OK, right? This is not all. This is one sense. 
It's still a creative process, yeah. 
Valuation project that you have to take it seriously. 
Alright, now I'm like. I don't know what I'm folding around, all right. 
You know, we don't have to make more, though. Yeah, I think we're fine with the ones that we have, we can. Already make a tree. We just need to put. It together? Yeah, we just need to Polish them a little because they are some of. Them are falling apart. 
Uh. No. Yeah. 
Yeah, like this one. But if. Have more we can include them. We can. They can be a prison. Or something that's. That's what they are. Yeah, they needed that. Thanks. Thank you. 
Wait. 
And then. This one is fixed, kind of. And this one is working fine. I'm going to. It's fine. It doesn't have to be very. Big. As you can see, the tree will be. 
To be so pretty. 
Stump it deep. We can glue the ornaments well, keep them. It's fine. 
It was like walking through the PMB with my little origami box. Well, everybody was like milling the metal. 
Talking with you. 
Are they state? No. But like with this line. 
We can. Yeah, we can do like this. 
We will have more, yeah. 
Let's see if this works. 
I think that the key is like the really hard increases, yeah. 
I think it's perfect size, yeah. 
The woman. 
Wait, when we have the star and the ornaments, it's going to be adorable. Is that? 
You can't take it. 
On those, we can put Christmas music in the in the back of the video. 
And we can. Put the effect of like snow and snowflakes. 
Ohh my gosh. 
Such a girl, but. 
I love it. 
Yeah. 
No. Can I? You have to fold the the this. Otherwise it's not going to. Yeah. 
Mm-hmm. 
How can I put it? Wait, we need to still put the other cube on. 
Top it's like, but it can be. Yeah. Typed with the star first. 
Yeah. Ohh yeah yeah. To make a steak. The star in the shade of the tree. 
We. 
You didn't know why the job to start singing. No, you said wait. It was very fun. OK, all the ornaments are cut. If we need more, I can quickly make more. 
Looks so weird. 
Are you trying to glue the? What is? Why are you putting a? Trying perfect to put it inside of the tree 1. Stick. 
Right. For some. 
Ohh wait, wait. 
Now. 
This one is. A little bit. That they're looking. 
Wow. 
Now you can put the star. 
I don't know what do you teach them? Oh. 
Yeah. 
To be honest, when we said like a picture, I was picturing something big. Well, but then we started the. 
Video the YouTube video. 
For an Ant this is big. Exactly. It's more than human design. ohh 
OK. 
Let's add the other ornaments. It's a bit weird that the the tree is yellow. It's like a butter. Yeah. 
Where does this go? Oh, my goodness, babe stick. 
Yeah, this. 
Oh. 
Ohh. 
Wait, we're missing the warning. What do you think? Would you put it in your house? Would. You buy it. 
Oh yeah, actually. 
Postmodern present. You can make the lines of the present that make put a little bow on it. Ohh. 
Ohh go. 
It's so big for the tree. 
Person. 
It's like a little worm. Wait, the star is so good. 
It's you, it's my only. 
Do that. Oh no. OK, how am I going to make both? 
Perfect. 
Good. 
It's. Kind of be more safe to reinforce the. 
Start here. Make it like a ribbon for it. Honestly, without scissors, we're doing pretty well, yeah. 
OK. 
Sure. 
It's so cute. 
Yes. 
Show to the camera. 
We we're missing the gift, no? 
Oh. 
But the tree is completed. This can be a corner of the room. Beautiful. 
Actually. 
Here. 
Always thinking that you could just paint it. With. Yeah. You're making your life harder. 
Red. And red, yeah. 
Oh yeah, or pink, whatever you prefer Christmassy. Yeah, we didn't use red that much, no. Yeah. I'm very proud. Too I will actually put it in My Portfolio. 
The first, the top part, the first project on the top. Like how was class? It's great. 
Understand. Yeah. 
I'm making the the little bow. So this is a bow. Oh, you made. 
I have a tiny one. Yeah. Ohh. 
A good call. Yeah, let's no, let's keep that one. 
I'm gonna take. Like doing like surgery. We've seen those people on Instagram who move the like dolls or the. 
Yeah. 
Little frog. 
Ohh so. What? The movie The frog. 
I'll show you. 
So cute. 
Let's make a close up. You can make it in. What is this? The corner of the room. 
And the. 
Does it the beer? 
No. 
Wait, we should write Merry Christmas too. Yeah, yeah. 
Absolutely. 
Wow. 
Is it? It's a little weird. Makes sense. 
This. 
Yeah. 
I think now. We can stop, yeah. Last Thursday. 
\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af15935-9b9f-4ec6-a73a-5d7c82f11784",
   "metadata": {},
   "source": [
    "### Simple approach: split at the spaces\n",
    "A common strategy is to \"split\" the text wherever one encounters spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3d70ce-4e3e-414a-877a-1e3ee7462c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Well', 'the', 'design', 'has', 'developed', 'a', 'wee', 'bit', 'since', 'you', 'saw', 'it', 'last', 'time,', 'the', 'design', 'obviously', 'is', 'still', 'in', 'exactly', 'the', 'same', 'place', 'but', 'the', 'design', 'is', 'extended', 'to', 'actually', 'include', 'the', 'actual', 'cremator', 'facility,', 'so', 'if', 'I', 'can', 'start', 'with', 'this', 'particular', 'drawing,', 'you’ve', 'seen', 'a', 'version', 'of', 'this', 'drawing', 'before.', 'Basically', 'we’re', 'arriving', 'in', 'the', 'new', 'car', 'park', 'in', 'this', 'area', 'and', 'from', 'the', 'car', 'park', 'we’ll', 'enter', 'the', 'building', 'through', 'a', 'waiting', 'area.', 'This', 'leads', 'us', 'to', 'the', 'first', 'query', 'I', 'have', 'because', 'there', 'was', 'some', 'discussion', 'about', 'whether', 'you', 'wanted', 'the', 'size', 'of', 'the', 'waiting', 'room', 'increased.', 'At', 'the', 'moment', 'it’s', 'exactly', 'on', 'brief,', 'but', 'it', 'does', 'look', 'kind', 'of', 'small', 'to', 'my', 'eye', 'in', 'relation', 'to', 'the', 'size', 'of', 'the', 'project.']\n"
     ]
    }
   ],
   "source": [
    "tokens = sample_text.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8c859-e96c-41b1-b140-a1f0326fee8d",
   "metadata": {},
   "source": [
    "### Preferred Approach: Use an existing library.\n",
    "Note the punctuations in the above output. They are still part of the preceding word. \n",
    "Also note contractions like `you've`. They are retained as they are. \n",
    "There are different ways to separate punctuations, contractions etc., but thankfully we can use a pre-existing library called [Natural Language Toolkit or NLTK](https://www.nltk.org/index.html#). To generate tokens, we will use a function called [word_tokenize](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ce9434-2bbf-4a9d-aa9e-6576f7de3ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Well', 'the', 'design', 'has', 'developed', 'a', 'wee', 'bit', 'since', 'you', 'saw', 'it', 'last', 'time', ',', 'the', 'design', 'obviously', 'is', 'still', 'in', 'exactly', 'the', 'same', 'place', 'but', 'the', 'design', 'is', 'extended', 'to', 'actually', 'include', 'the', 'actual', 'cremator', 'facility', ',', 'so', 'if', 'I', 'can', 'start', 'with', 'this', 'particular', 'drawing', ',', 'you', '’', 've', 'seen', 'a', 'version', 'of', 'this', 'drawing', 'before', '.', 'Basically', 'we', '’', 're', 'arriving', 'in', 'the', 'new', 'car', 'park', 'in', 'this', 'area', 'and', 'from', 'the', 'car', 'park', 'we', '’', 'll', 'enter', 'the', 'building', 'through', 'a', 'waiting', 'area', '.', 'This', 'leads', 'us', 'to', 'the', 'first', 'query', 'I', 'have', 'because', 'there', 'was', 'some', 'discussion', 'about', 'whether', 'you', 'wanted', 'the', 'size', 'of', 'the', 'waiting', 'room', 'increased', '.', 'At', 'the', 'moment', 'it', '’', 's', 'exactly', 'on', 'brief', ',', 'but', 'it', 'does', 'look', 'kind', 'of', 'small', 'to', 'my', 'eye', 'in', 'relation', 'to', 'the', 'size', 'of', 'the', 'project', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/schandrasegara/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')  # comment this line after the first time you run this code.\n",
    "from nltk import word_tokenize\n",
    "tokens = word_tokenize(sample_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202c14b-5d59-4fbc-91cc-1092dae6fcad",
   "metadata": {},
   "source": [
    "### Removing Punctuations\n",
    "Different approaches can be used to remove punctuations. A helpful way is to use another library called [string](https://docs.python.org/3/library/string.html), which contains a list of standard punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86eae962-46e9-4f9b-8316-d16a34f64c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Well', 'the', 'design', 'has', 'developed', 'a', 'wee', 'bit', 'since', 'you', 'saw', 'it', 'last', 'time', 'the', 'design', 'obviously', 'is', 'still', 'in', 'exactly', 'the', 'same', 'place', 'but', 'the', 'design', 'is', 'extended', 'to', 'actually', 'include', 'the', 'actual', 'cremator', 'facility', 'so', 'if', 'I', 'can', 'start', 'with', 'this', 'particular', 'drawing', 'you', 've', 'seen', 'a', 'version', 'of', 'this', 'drawing', 'before', 'Basically', 'we', 're', 'arriving', 'in', 'the', 'new', 'car', 'park', 'in', 'this', 'area', 'and', 'from', 'the', 'car', 'park', 'we', 'll', 'enter', 'the', 'building', 'through', 'a', 'waiting', 'area', 'This', 'leads', 'us', 'to', 'the', 'first', 'query', 'I', 'have', 'because', 'there', 'was', 'some', 'discussion', 'about', 'whether', 'you', 'wanted', 'the', 'size', 'of', 'the', 'waiting', 'room', 'increased', 'At', 'the', 'moment', 'it', 's', 'exactly', 'on', 'brief', 'but', 'it', 'does', 'look', 'kind', 'of', 'small', 'to', 'my', 'eye', 'in', 'relation', 'to', 'the', 'size', 'of', 'the', 'project']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuations = string.punctuation + '’'\n",
    "tokens_without_puncts = [word for word in tokens if word not in punctuations]\n",
    "print(tokens_without_puncts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3d663-a1a8-4155-bee6-e7c33de23ef5",
   "metadata": {},
   "source": [
    "## Counting Words\n",
    "Almost subsequent processing is about counting words at some level. A simple way to get a count of words for us is to use another library called [collections](https://docs.python.org/3/library/collections.html), and a function called [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5632f4a8-57ac-4c56-9798-6c2b4d7a4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter(tokens_without_puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abfa5132-3d00-4d76-997c-6b4316334eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 14, 'in': 4, 'to': 4, 'of': 4, 'design': 3, 'a': 3, 'you': 3, 'it': 3, 'this': 3, 'is': 2, 'exactly': 2, 'but': 2, 'I': 2, 'drawing': 2, 'we': 2, 'car': 2, 'park': 2, 'area': 2, 'waiting': 2, 'size': 2, 'Well': 1, 'has': 1, 'developed': 1, 'wee': 1, 'bit': 1, 'since': 1, 'saw': 1, 'last': 1, 'time': 1, 'obviously': 1, 'still': 1, 'same': 1, 'place': 1, 'extended': 1, 'actually': 1, 'include': 1, 'actual': 1, 'cremator': 1, 'facility': 1, 'so': 1, 'if': 1, 'can': 1, 'start': 1, 'with': 1, 'particular': 1, 've': 1, 'seen': 1, 'version': 1, 'before': 1, 'Basically': 1, 're': 1, 'arriving': 1, 'new': 1, 'and': 1, 'from': 1, 'll': 1, 'enter': 1, 'building': 1, 'through': 1, 'This': 1, 'leads': 1, 'us': 1, 'first': 1, 'query': 1, 'have': 1, 'because': 1, 'there': 1, 'was': 1, 'some': 1, 'discussion': 1, 'about': 1, 'whether': 1, 'wanted': 1, 'room': 1, 'increased': 1, 'At': 1, 'moment': 1, 's': 1, 'on': 1, 'brief': 1, 'does': 1, 'look': 1, 'kind': 1, 'small': 1, 'my': 1, 'eye': 1, 'relation': 1, 'project': 1})\n"
     ]
    }
   ],
   "source": [
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7218f-8268-44f8-902a-879beb925ec6",
   "metadata": {},
   "source": [
    "## Letter case\n",
    "Looking at the list of non-repeating words in the sample text, we can see that capitalised letters are treated differently.\n",
    "We may or may not want this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608cb938-19f3-4927-a17a-bbde22460cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At', 'Basically', 'I', 'This', 'Well', 'a', 'about', 'actual', 'actually', 'and', 'area', 'arriving', 'because', 'before', 'bit', 'brief', 'building', 'but', 'can', 'car', 'cremator', 'design', 'developed', 'discussion', 'does', 'drawing', 'enter', 'exactly', 'extended', 'eye', 'facility', 'first', 'from', 'has', 'have', 'if', 'in', 'include', 'increased', 'is', 'it', 'kind', 'last', 'leads', 'll', 'look', 'moment', 'my', 'new', 'obviously', 'of', 'on', 'park', 'particular', 'place', 'project', 'query', 're', 'relation', 'room', 's', 'same', 'saw', 'seen', 'since', 'size', 'small', 'so', 'some', 'start', 'still', 'the', 'there', 'this', 'through', 'time', 'to', 'us', 've', 'version', 'waiting', 'wanted', 'was', 'we', 'wee', 'whether', 'with', 'you']\n"
     ]
    }
   ],
   "source": [
    "non_repeating_words = word_counts.keys()\n",
    "print(sorted(non_repeating_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e753e9-eabc-41df-a661-269b41cb9808",
   "metadata": {},
   "source": [
    "### Converting all text to lowercase\n",
    "\n",
    "We simply use the `.lower()` method to convert all text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b5bcbf-f6a6-4e3f-9963-9fa23575fb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 14, 'in': 4, 'to': 4, 'this': 4, 'of': 4, 'design': 3, 'a': 3, 'you': 3, 'it': 3, 'is': 2, 'exactly': 2, 'but': 2, 'i': 2, 'drawing': 2, 'we': 2, 'car': 2, 'park': 2, 'area': 2, 'waiting': 2, 'size': 2, 'well': 1, 'has': 1, 'developed': 1, 'wee': 1, 'bit': 1, 'since': 1, 'saw': 1, 'last': 1, 'time': 1, 'obviously': 1, 'still': 1, 'same': 1, 'place': 1, 'extended': 1, 'actually': 1, 'include': 1, 'actual': 1, 'cremator': 1, 'facility': 1, 'so': 1, 'if': 1, 'can': 1, 'start': 1, 'with': 1, 'particular': 1, 've': 1, 'seen': 1, 'version': 1, 'before': 1, 'basically': 1, 're': 1, 'arriving': 1, 'new': 1, 'and': 1, 'from': 1, 'll': 1, 'enter': 1, 'building': 1, 'through': 1, 'leads': 1, 'us': 1, 'first': 1, 'query': 1, 'have': 1, 'because': 1, 'there': 1, 'was': 1, 'some': 1, 'discussion': 1, 'about': 1, 'whether': 1, 'wanted': 1, 'room': 1, 'increased': 1, 'at': 1, 'moment': 1, 's': 1, 'on': 1, 'brief': 1, 'does': 1, 'look': 1, 'kind': 1, 'small': 1, 'my': 1, 'eye': 1, 'relation': 1, 'project': 1})\n"
     ]
    }
   ],
   "source": [
    "lowercase_tokens = [word.lower() for word in tokens_without_puncts]\n",
    "word_counts_lowercase = Counter(lowercase_tokens)\n",
    "print(word_counts_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04417bce-ee96-4298-aea6-847f041858d3",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "Note how `actual` and `actually` are treated separately. This may be necessary, or not, depending on the requirements of the analysis. If the base form of the word is to be obtained, we either have to \"stem\" the word (remove suffixes) or \"lemmatize\" the word (convert to base form).\n",
    "\n",
    "### Stemming\n",
    "\n",
    "This is the simple form where a set of rules can be used to remove inflection from the words. This may or may not work, as you can see from the below two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44fac450-6004-4b22-8ac7-08335a7b640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discussion : discuss\n",
      "went : went\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(\"discussion :\", stemmer.stem(\"discussion\"))\n",
    "print(\"went :\", stemmer.stem(\"went\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00997f3-c8ef-4265-988a-66f4bb9627ae",
   "metadata": {},
   "source": [
    "Applying this approach to our word list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed716ed2-1f36-4940-bd76-0e25dcbfb8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'the', 'design', 'ha', 'develop', 'a', 'wee', 'bit', 'sinc', 'you', 'saw', 'it', 'last', 'time', 'obvious', 'is', 'still', 'in', 'exactli', 'same', 'place', 'but', 'extend', 'to', 'actual', 'includ', 'actual', 'cremat', 'facil', 'so', 'if', 'i', 'can', 'start', 'with', 'thi', 'particular', 'draw', 've', 'seen', 'version', 'of', 'befor', 'basic', 'we', 're', 'arriv', 'new', 'car', 'park', 'area', 'and', 'from', 'll', 'enter', 'build', 'through', 'wait', 'lead', 'us', 'first', 'queri', 'have', 'becaus', 'there', 'wa', 'some', 'discuss', 'about', 'whether', 'want', 'size', 'room', 'increas', 'at', 'moment', 's', 'on', 'brief', 'doe', 'look', 'kind', 'small', 'my', 'eye', 'relat', 'project']\n"
     ]
    }
   ],
   "source": [
    "stems = [stemmer.stem(word) for word in word_counts_lowercase]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8dfe9-bf88-40e9-a2e0-234031d91d60",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "This is a slightly more sophisticated version, where grammatical considerations are used to determine the base form of the word. For this, we also need to label the word with its appropriate part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62a23ebf-04ad-47cb-964f-82077c0420c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/schandrasegara/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/schandrasegara/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discussion : discussion\n",
      "went : go\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')  # comment this line after the first time you run this code.\n",
    "nltk.download('averaged_perceptron_tagger_eng')  # comment this line after the first time you run this code.\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "lemmatize = WordNetLemmatizer().lemmatize\n",
    "print(\"discussion :\", lemmatize(\"discussion\", pos=\"n\"))\n",
    "print(\"went :\", lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e27af-dc85-4fe0-879f-4f2b0ae3dafb",
   "metadata": {},
   "source": [
    "Applying it to our list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805bc250-3f8e-491d-a29d-832649eeae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'the', 'design', 'have', 'develop', 'a', 'wee', 'bit', 'since', 'you', 'saw', 'it', 'last', 'time', 'the', 'design', 'obviously', 'be', 'still', 'in', 'exactly', 'the', 'same', 'place', 'but', 'the', 'design', 'be', 'extend', 'to', 'actually', 'include', 'the', 'actual', 'cremator', 'facility', 'so', 'if', 'i', 'can', 'start', 'with', 'this', 'particular', 'drawing', 'you', 've', 'see', 'a', 'version', 'of', 'this', 'draw', 'before', 'basically', 'we', 're', 'arrive', 'in', 'the', 'new', 'car', 'park', 'in', 'this', 'area', 'and', 'from', 'the', 'car', 'park', 'we', 'll', 'enter', 'the', 'building', 'through', 'a', 'wait', 'area', 'this', 'lead', 'u', 'to', 'the', 'first', 'query', 'i', 'have', 'because', 'there', 'be', 'some', 'discussion', 'about', 'whether', 'you', 'want', 'the', 'size', 'of', 'the', 'wait', 'room', 'increase', 'at', 'the', 'moment', 'it', 's', 'exactly', 'on', 'brief', 'but', 'it', 'do', 'look', 'kind', 'of', 'small', 'to', 'my', 'eye', 'in', 'relation', 'to', 'the', 'size', 'of', 'the', 'project']\n"
     ]
    }
   ],
   "source": [
    "tagged_tokens = pos_tag(lowercase_tokens)\n",
    "lemmas_list = []\n",
    "\n",
    "for tagged_word in tagged_tokens:\n",
    "    word, pos_tag = tagged_word\n",
    "    if pos_tag.startswith(\"V\") :\n",
    "        lemma = lemmatize(word, pos=\"v\")\n",
    "    elif pos_tag.startswith(\"R\") :\n",
    "        lemma = lemmatize(word, pos=\"r\")\n",
    "    elif pos_tag.startswith(\"N\") :\n",
    "        lemma = lemmatize(word, pos=\"n\")\n",
    "    elif pos_tag.startswith(\"J\") :\n",
    "        lemma = lemmatize(word, pos=\"a\")\n",
    "    else :\n",
    "        lemma = lemmatize(word)\n",
    "    lemmas_list.append(lemma)\n",
    "\n",
    "print(lemmas_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcd91b-869d-4740-adc3-0a57738c1c00",
   "metadata": {},
   "source": [
    "What difference do you see between the two lists?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b58d10-2284-4088-b2b1-0c5d13ac4e9a",
   "metadata": {},
   "source": [
    "## Extracting n-grams from text\n",
    "\n",
    "For identifying commonly-used phrases in a given text, you need to capture all possible occurrences of word sequences of the length that interests you.\n",
    "\n",
    "### Bigrams\n",
    "If the sequence is of two words, it is called a bigram. There is a function in the NLTK library, which is called `bigrams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7790bd-5f75-46c9-82c4-3a6e6a07eeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('well', 'the'), ('the', 'design'), ('design', 'has'), ('has', 'developed'), ('developed', 'a'), ('a', 'wee'), ('wee', 'bit'), ('bit', 'since'), ('since', 'you'), ('you', 'saw'), ('saw', 'it'), ('it', 'last'), ('last', 'time'), ('time', 'the'), ('the', 'design'), ('design', 'obviously'), ('obviously', 'is'), ('is', 'still'), ('still', 'in'), ('in', 'exactly'), ('exactly', 'the'), ('the', 'same'), ('same', 'place'), ('place', 'but'), ('but', 'the'), ('the', 'design'), ('design', 'is'), ('is', 'extended'), ('extended', 'to'), ('to', 'actually'), ('actually', 'include'), ('include', 'the'), ('the', 'actual'), ('actual', 'cremator'), ('cremator', 'facility'), ('facility', 'so'), ('so', 'if'), ('if', 'i'), ('i', 'can'), ('can', 'start'), ('start', 'with'), ('with', 'this'), ('this', 'particular'), ('particular', 'drawing'), ('drawing', 'you'), ('you', 've'), ('ve', 'seen'), ('seen', 'a'), ('a', 'version'), ('version', 'of'), ('of', 'this'), ('this', 'drawing'), ('drawing', 'before'), ('before', 'basically'), ('basically', 'we'), ('we', 're'), ('re', 'arriving'), ('arriving', 'in'), ('in', 'the'), ('the', 'new'), ('new', 'car'), ('car', 'park'), ('park', 'in'), ('in', 'this'), ('this', 'area'), ('area', 'and'), ('and', 'from'), ('from', 'the'), ('the', 'car'), ('car', 'park'), ('park', 'we'), ('we', 'll'), ('ll', 'enter'), ('enter', 'the'), ('the', 'building'), ('building', 'through'), ('through', 'a'), ('a', 'waiting'), ('waiting', 'area'), ('area', 'this'), ('this', 'leads'), ('leads', 'us'), ('us', 'to'), ('to', 'the'), ('the', 'first'), ('first', 'query'), ('query', 'i'), ('i', 'have'), ('have', 'because'), ('because', 'there'), ('there', 'was'), ('was', 'some'), ('some', 'discussion'), ('discussion', 'about'), ('about', 'whether'), ('whether', 'you'), ('you', 'wanted'), ('wanted', 'the'), ('the', 'size'), ('size', 'of'), ('of', 'the'), ('the', 'waiting'), ('waiting', 'room'), ('room', 'increased'), ('increased', 'at'), ('at', 'the'), ('the', 'moment'), ('moment', 'it'), ('it', 's'), ('s', 'exactly'), ('exactly', 'on'), ('on', 'brief'), ('brief', 'but'), ('but', 'it'), ('it', 'does'), ('does', 'look'), ('look', 'kind'), ('kind', 'of'), ('of', 'small'), ('small', 'to'), ('to', 'my'), ('my', 'eye'), ('eye', 'in'), ('in', 'relation'), ('relation', 'to'), ('to', 'the'), ('the', 'size'), ('size', 'of'), ('of', 'the'), ('the', 'project')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import bigrams\n",
    "bigrams_from_text = list(bigrams(lowercase_tokens))\n",
    "print(bigrams_from_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b7969-1017-4f8c-9468-bc2eb87cb546",
   "metadata": {},
   "source": [
    "### Counting bigrams\n",
    "It is then a matter of simply counting the number of occurrences, similar to what we had done with words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f72bcd58-3820-4ce8-bd65-b71f8e543bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the', 'design'): 3, ('car', 'park'): 2, ('to', 'the'): 2, ('the', 'size'): 2, ('size', 'of'): 2, ('of', 'the'): 2, ('well', 'the'): 1, ('design', 'has'): 1, ('has', 'developed'): 1, ('developed', 'a'): 1, ('a', 'wee'): 1, ('wee', 'bit'): 1, ('bit', 'since'): 1, ('since', 'you'): 1, ('you', 'saw'): 1, ('saw', 'it'): 1, ('it', 'last'): 1, ('last', 'time'): 1, ('time', 'the'): 1, ('design', 'obviously'): 1, ('obviously', 'is'): 1, ('is', 'still'): 1, ('still', 'in'): 1, ('in', 'exactly'): 1, ('exactly', 'the'): 1, ('the', 'same'): 1, ('same', 'place'): 1, ('place', 'but'): 1, ('but', 'the'): 1, ('design', 'is'): 1, ('is', 'extended'): 1, ('extended', 'to'): 1, ('to', 'actually'): 1, ('actually', 'include'): 1, ('include', 'the'): 1, ('the', 'actual'): 1, ('actual', 'cremator'): 1, ('cremator', 'facility'): 1, ('facility', 'so'): 1, ('so', 'if'): 1, ('if', 'i'): 1, ('i', 'can'): 1, ('can', 'start'): 1, ('start', 'with'): 1, ('with', 'this'): 1, ('this', 'particular'): 1, ('particular', 'drawing'): 1, ('drawing', 'you'): 1, ('you', 've'): 1, ('ve', 'seen'): 1, ('seen', 'a'): 1, ('a', 'version'): 1, ('version', 'of'): 1, ('of', 'this'): 1, ('this', 'drawing'): 1, ('drawing', 'before'): 1, ('before', 'basically'): 1, ('basically', 'we'): 1, ('we', 're'): 1, ('re', 'arriving'): 1, ('arriving', 'in'): 1, ('in', 'the'): 1, ('the', 'new'): 1, ('new', 'car'): 1, ('park', 'in'): 1, ('in', 'this'): 1, ('this', 'area'): 1, ('area', 'and'): 1, ('and', 'from'): 1, ('from', 'the'): 1, ('the', 'car'): 1, ('park', 'we'): 1, ('we', 'll'): 1, ('ll', 'enter'): 1, ('enter', 'the'): 1, ('the', 'building'): 1, ('building', 'through'): 1, ('through', 'a'): 1, ('a', 'waiting'): 1, ('waiting', 'area'): 1, ('area', 'this'): 1, ('this', 'leads'): 1, ('leads', 'us'): 1, ('us', 'to'): 1, ('the', 'first'): 1, ('first', 'query'): 1, ('query', 'i'): 1, ('i', 'have'): 1, ('have', 'because'): 1, ('because', 'there'): 1, ('there', 'was'): 1, ('was', 'some'): 1, ('some', 'discussion'): 1, ('discussion', 'about'): 1, ('about', 'whether'): 1, ('whether', 'you'): 1, ('you', 'wanted'): 1, ('wanted', 'the'): 1, ('the', 'waiting'): 1, ('waiting', 'room'): 1, ('room', 'increased'): 1, ('increased', 'at'): 1, ('at', 'the'): 1, ('the', 'moment'): 1, ('moment', 'it'): 1, ('it', 's'): 1, ('s', 'exactly'): 1, ('exactly', 'on'): 1, ('on', 'brief'): 1, ('brief', 'but'): 1, ('but', 'it'): 1, ('it', 'does'): 1, ('does', 'look'): 1, ('look', 'kind'): 1, ('kind', 'of'): 1, ('of', 'small'): 1, ('small', 'to'): 1, ('to', 'my'): 1, ('my', 'eye'): 1, ('eye', 'in'): 1, ('in', 'relation'): 1, ('relation', 'to'): 1, ('the', 'project'): 1})\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = Counter(bigrams_from_text)\n",
    "print(bigram_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3aae1-bb5c-480b-964e-b8ac438c28e1",
   "metadata": {},
   "source": [
    "### Generalizing to n-grams\n",
    "We use a similar utility called `n-grams` to generalize this idea to words of any length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68bf9daf-a998-420f-b6a6-ae29afbb66bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the', 'size', 'of'): 2, ('size', 'of', 'the'): 2, ('well', 'the', 'design'): 1, ('the', 'design', 'has'): 1, ('design', 'has', 'developed'): 1, ('has', 'developed', 'a'): 1, ('developed', 'a', 'wee'): 1, ('a', 'wee', 'bit'): 1, ('wee', 'bit', 'since'): 1, ('bit', 'since', 'you'): 1, ('since', 'you', 'saw'): 1, ('you', 'saw', 'it'): 1, ('saw', 'it', 'last'): 1, ('it', 'last', 'time'): 1, ('last', 'time', 'the'): 1, ('time', 'the', 'design'): 1, ('the', 'design', 'obviously'): 1, ('design', 'obviously', 'is'): 1, ('obviously', 'is', 'still'): 1, ('is', 'still', 'in'): 1, ('still', 'in', 'exactly'): 1, ('in', 'exactly', 'the'): 1, ('exactly', 'the', 'same'): 1, ('the', 'same', 'place'): 1, ('same', 'place', 'but'): 1, ('place', 'but', 'the'): 1, ('but', 'the', 'design'): 1, ('the', 'design', 'is'): 1, ('design', 'is', 'extended'): 1, ('is', 'extended', 'to'): 1, ('extended', 'to', 'actually'): 1, ('to', 'actually', 'include'): 1, ('actually', 'include', 'the'): 1, ('include', 'the', 'actual'): 1, ('the', 'actual', 'cremator'): 1, ('actual', 'cremator', 'facility'): 1, ('cremator', 'facility', 'so'): 1, ('facility', 'so', 'if'): 1, ('so', 'if', 'i'): 1, ('if', 'i', 'can'): 1, ('i', 'can', 'start'): 1, ('can', 'start', 'with'): 1, ('start', 'with', 'this'): 1, ('with', 'this', 'particular'): 1, ('this', 'particular', 'drawing'): 1, ('particular', 'drawing', 'you'): 1, ('drawing', 'you', 've'): 1, ('you', 've', 'seen'): 1, ('ve', 'seen', 'a'): 1, ('seen', 'a', 'version'): 1, ('a', 'version', 'of'): 1, ('version', 'of', 'this'): 1, ('of', 'this', 'drawing'): 1, ('this', 'drawing', 'before'): 1, ('drawing', 'before', 'basically'): 1, ('before', 'basically', 'we'): 1, ('basically', 'we', 're'): 1, ('we', 're', 'arriving'): 1, ('re', 'arriving', 'in'): 1, ('arriving', 'in', 'the'): 1, ('in', 'the', 'new'): 1, ('the', 'new', 'car'): 1, ('new', 'car', 'park'): 1, ('car', 'park', 'in'): 1, ('park', 'in', 'this'): 1, ('in', 'this', 'area'): 1, ('this', 'area', 'and'): 1, ('area', 'and', 'from'): 1, ('and', 'from', 'the'): 1, ('from', 'the', 'car'): 1, ('the', 'car', 'park'): 1, ('car', 'park', 'we'): 1, ('park', 'we', 'll'): 1, ('we', 'll', 'enter'): 1, ('ll', 'enter', 'the'): 1, ('enter', 'the', 'building'): 1, ('the', 'building', 'through'): 1, ('building', 'through', 'a'): 1, ('through', 'a', 'waiting'): 1, ('a', 'waiting', 'area'): 1, ('waiting', 'area', 'this'): 1, ('area', 'this', 'leads'): 1, ('this', 'leads', 'us'): 1, ('leads', 'us', 'to'): 1, ('us', 'to', 'the'): 1, ('to', 'the', 'first'): 1, ('the', 'first', 'query'): 1, ('first', 'query', 'i'): 1, ('query', 'i', 'have'): 1, ('i', 'have', 'because'): 1, ('have', 'because', 'there'): 1, ('because', 'there', 'was'): 1, ('there', 'was', 'some'): 1, ('was', 'some', 'discussion'): 1, ('some', 'discussion', 'about'): 1, ('discussion', 'about', 'whether'): 1, ('about', 'whether', 'you'): 1, ('whether', 'you', 'wanted'): 1, ('you', 'wanted', 'the'): 1, ('wanted', 'the', 'size'): 1, ('of', 'the', 'waiting'): 1, ('the', 'waiting', 'room'): 1, ('waiting', 'room', 'increased'): 1, ('room', 'increased', 'at'): 1, ('increased', 'at', 'the'): 1, ('at', 'the', 'moment'): 1, ('the', 'moment', 'it'): 1, ('moment', 'it', 's'): 1, ('it', 's', 'exactly'): 1, ('s', 'exactly', 'on'): 1, ('exactly', 'on', 'brief'): 1, ('on', 'brief', 'but'): 1, ('brief', 'but', 'it'): 1, ('but', 'it', 'does'): 1, ('it', 'does', 'look'): 1, ('does', 'look', 'kind'): 1, ('look', 'kind', 'of'): 1, ('kind', 'of', 'small'): 1, ('of', 'small', 'to'): 1, ('small', 'to', 'my'): 1, ('to', 'my', 'eye'): 1, ('my', 'eye', 'in'): 1, ('eye', 'in', 'relation'): 1, ('in', 'relation', 'to'): 1, ('relation', 'to', 'the'): 1, ('to', 'the', 'size'): 1, ('of', 'the', 'project'): 1})\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "trigrams_from_text = list(ngrams(lowercase_tokens, 3))\n",
    "trigram_counts = Counter(trigrams_from_text)\n",
    "print(trigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee7056b7-4c7d-4e9d-8c86-16a49a8391e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['draw', 'draw', 'draw', 'drawer', 'draw']\n"
     ]
    }
   ],
   "source": [
    "test_words = ['draw', 'drawing', 'drew', 'drawer', 'drawn']\n",
    "lemmas_test = [lemmatize(w, 'v') for w in test_words]\n",
    "print(lemmas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a04507d8-4ca4-4867-bb90-8fcf92fd1973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['draw', 'draw', 'drew', 'drawer', 'drawn']\n"
     ]
    }
   ],
   "source": [
    "stems_test = [stemmer.stem(w) for w in test_words]\n",
    "print(stems_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2396ff-825c-40d2-bb71-c785037fe5f8",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "Some words can be seen to contain less \"information\" than others. The commonly-occurring words are called \"stop words\". There is a library that does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88539f08-4f05-4db3-9cf2-a21ed3e74ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"that'll\", 'be', 'hers', 'any', 'while', 'whom', 'how', 'few', \"won't\", 'through', 't', \"haven't\", 'then', 'which', 'but', \"you'll\", 'his', 'on', \"didn't\", 'hasn', 'will', 'only', 'it', \"aren't\", 'don', 'until', 'during', 'this', 'herself', 'have', 'ma', 'no', 'ourselves', 'our', 'of', 'from', 'your', \"doesn't\", 'does', 'with', 'their', 'a', 'my', 'so', 'than', 'yourself', 'itself', \"you're\", 'having', 'himself', 'over', 'needn', 'should', \"shan't\", \"mightn't\", 'they', 'y', 'an', 'who', 'the', 'again', 'shouldn', 'wasn', 'if', 'very', 'has', 'under', 'too', 'doesn', 'or', \"you've\", 'am', 'for', 'off', 'haven', 'up', 'after', 'there', 'she', \"hadn't\", 'them', 'such', 'myself', \"couldn't\", 'yourselves', 'ours', 'at', 'm', 'yours', 're', 'did', 'couldn', 'i', 'into', 've', \"needn't\", \"shouldn't\", 'isn', 'we', 'each', 'about', \"wasn't\", 'against', 'more', 'are', 'because', 'same', 'can', 'not', 'her', 'is', \"don't\", 'to', 'by', 'where', 'what', 'had', 'before', \"hasn't\", 'do', 'further', 'he', 'its', 'down', 'those', 'why', 'when', 'these', 'out', 'hadn', 'd', 'all', 'once', 'as', 'didn', 'shan', 'in', 'here', 's', 'me', 'aren', 'weren', 'now', 'just', 'that', 'were', 'been', 'and', \"isn't\", 'mightn', 'him', 'mustn', 'wouldn', 'above', 'was', 'some', \"you'd\", \"weren't\", 'you', \"she's\", \"should've\", 'themselves', 'below', \"mustn't\", 'o', 'being', 'both', 'other', 'theirs', 'ain', \"it's\", 'nor', 'doing', 'between', 'most', 'own', 'll', 'won', \"wouldn't\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/schandrasegara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') # comment this line after the first time you run this code.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "603b9070-5c68-46aa-8920-e5aebee5b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'design': 3, 'exactly': 2, 'drawing': 2, 'car': 2, 'park': 2, 'area': 2, 'waiting': 2, 'size': 2, 'well': 1, 'developed': 1, 'wee': 1, 'bit': 1, 'since': 1, 'saw': 1, 'last': 1, 'time': 1, 'obviously': 1, 'still': 1, 'place': 1, 'extended': 1, 'actually': 1, 'include': 1, 'actual': 1, 'cremator': 1, 'facility': 1, 'start': 1, 'particular': 1, 'seen': 1, 'version': 1, 'basically': 1, 'arriving': 1, 'new': 1, 'enter': 1, 'building': 1, 'leads': 1, 'us': 1, 'first': 1, 'query': 1, 'discussion': 1, 'whether': 1, 'wanted': 1, 'room': 1, 'increased': 1, 'moment': 1, 'brief': 1, 'look': 1, 'kind': 1, 'small': 1, 'eye': 1, 'relation': 1, 'project': 1})\n"
     ]
    }
   ],
   "source": [
    "lowercase_tokens_nostop = [word for word in lowercase_tokens if not word in stop_words]\n",
    "word_counts_lowercase_nostop = Counter(lowercase_tokens_nostop)\n",
    "print(word_counts_lowercase_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69078140-82d9-4093-ae25-89677e3b73ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
